# ğŸ–¼ï¸ Classification d'Images avec ResNet

<div align="center">
  <img src="https://img.shields.io/badge/Python-3.8%2B-blue.svg" alt="Python Version">
  <img src="https://img.shields.io/badge/PyTorch-2.1.0-red.svg" alt="PyTorch Version">
  <img src="https://img.shields.io/badge/License-MIT-green.svg" alt="License">
</div>

Ce projet implÃ©mente et Ã©value l'architecture ResNet (Residual Neural Networks) pour la classification d'images sur plusieurs datasets. Il fait partie d'un travail de recherche acadÃ©mique rÃ©alisÃ© dans le cadre du Master IMSD Ã  l'UniversitÃ© Ibn Zohr.

## ğŸ¯ Objectifs du Projet

- ImplÃ©menter l'architecture ResNet from scratch avec PyTorch
- Ã‰valuer les performances sur 4 datasets diffÃ©rents
- Comparer avec d'autres architectures (VGG, MobileNet, EfficientNet)
- Analyser l'impact des connexions rÃ©siduelles et techniques d'optimisation
- DÃ©montrer l'efficacitÃ© du transfer learning

## ğŸ“– RÃ©sumÃ© du Rapport

Ce projet explore l'utilisation des rÃ©seaux de neurones rÃ©siduels (ResNet) pour la classification d'images. ResNet a rÃ©volutionnÃ© l'apprentissage profond en 2015 en introduisant les connexions rÃ©siduelles (skip connections), permettant d'entraÃ®ner des rÃ©seaux trÃ¨s profonds sans souffrir du problÃ¨me de disparition du gradient.

### Contributions principales :
- ImplÃ©mentation complÃ¨te de ResNet avec blocs Basic et Bottleneck
- Ã‰valuation sur CIFAR-10, Fashion-MNIST, ImageNet et dataset personnalisÃ©
- Ã‰tudes d'ablation pour isoler l'impact de chaque composant
- Comparaison avec l'Ã©tat de l'art

## ğŸ§  Introduction Ã  ResNet

ResNet (Residual Networks) rÃ©sout le problÃ¨me de dÃ©gradation des rÃ©seaux trÃ¨s profonds grÃ¢ce aux **connexions rÃ©siduelles**. Au lieu d'apprendre une fonction `H(x)`, le rÃ©seau apprend une fonction rÃ©siduelle `F(x) = H(x) - x`.

```
Input x â”€â”€â”
          â”‚
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Conv 3x3  â”‚
    â”‚   ReLU    â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
    â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
    â”‚ Conv 3x3  â”‚
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â–¼
       F(x) + x â”€â”€â”€â”€â–º Output
          â–²
          â”‚
          â””â”€ Skip Connection
```

### Avantages clÃ©s :
- **RÃ©sout la disparition du gradient** : gradient â‰¥ 1 grÃ¢ce aux skip connections
- **Permet des rÃ©seaux trÃ¨s profonds** : jusqu'Ã  1000+ couches
- **AmÃ©liore la convergence** : entraÃ®nement plus stable et rapide
- **Performance supÃ©rieure** : SOTA sur ImageNet en 2015

## ğŸ› ï¸ Installation

### PrÃ©requis
- Python 3.8+
- GPU avec CUDA (recommandÃ©)

### Installation des dÃ©pendances

```bash
# Cloner le repository
git clone https://github.com/marwaneouz/Image-Classification-with-ResNet.git
cd Image-Classification-with-ResNet

# CrÃ©er un environnement virtuel
python -m venv resnet_env
source resnet_env/bin/activate  # Linux/Mac
# ou
resnet_env\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

## ğŸš€ Utilisation

### 1. EntraÃ®nement rapide sur CIFAR-10

```bash
python src/training/train.py --dataset cifar10 --epochs 200 --batch_size 128
```

### 2. EntraÃ®nement avec configuration personnalisÃ©e

```bash
python src/training/train.py --config configs/cifar10_config.yaml
```

### 3. Ã‰valuation d'un modÃ¨le

```bash
python src/evaluation/evaluate.py --model_path results/models/resnet18_cifar10.pth --dataset cifar10
```

### 4. DÃ©monstration interactive

```bash
jupyter notebook notebooks/demo.ipynb
```

## ğŸ“Š RÃ©sultats Obtenus

### Performance globale

| Dataset | ModÃ¨le | Accuracy | Top-5 Error | ParamÃ¨tres |
|---------|--------|----------|-------------|------------|
| CIFAR-10 | ResNet-18 | **94.25%** | - | 11.7M |
| CIFAR-10 | ResNet-50 | **95.32%** | - | 25.6M |
| Fashion-MNIST | ResNet-18 | **92.32%** | - | 11.7M |
| ImageNet | ResNet-50 | **75.99%** | **7.02%** | 25.6M |

### Comparaison avec l'Ã©tat de l'art (CIFAR-10)

| ModÃ¨le | Accuracy | AnnÃ©e |
|--------|----------|-------|
| Notre ResNet-50 | **95.32%** | 2024 |
| DenseNet-190 | 96.54% | 2017 |
| PyramidNet-272 | 97.05% | 2017 |
| Vision Transformer | 98.13% | 2021 |

### Visualisations

#### Courbes d'apprentissage
![Training Curves](Resultat/training_curves_cifar10.jpg)

#### Matrice de confusion
![Confusion Matrix](Resultat/confusion_matrix_cifar10.webp)

## ğŸ“‚ Datasets UtilisÃ©s

### 1. CIFAR-10
- **60,000 images** couleur 32Ã—32 pixels
- **10 classes** : avion, automobile, oiseau, chat, cerf, chien, grenouille, cheval, bateau, camion
- **Split** : 50,000 train / 10,000 test

### 2. Fashion-MNIST
- **70,000 images** en niveaux de gris 28Ã—28 pixels
- **10 classes** de vÃªtements : T-shirt, pantalon, pullover, robe, manteau, sandale, chemise, sneaker, sac, bottine
- **Split** : 60,000 train / 10,000 test

### 3. ImageNet (subset)
- **1,000 classes** d'objets naturels
- **Images haute rÃ©solution** redimensionnÃ©es Ã  224Ã—224
- UtilisÃ© principalement pour le transfer learning

### 4. Dataset PersonnalisÃ©
- **4 classes** : Chat, Chien, Voiture, Fleur
- **1,180 images** dÃ©sÃ©quilibrÃ©es
- **Challenge** : gestion du dÃ©sÃ©quilibre des classes

## ğŸ”¬ Ã‰tudes d'Ablation

### Impact des connexions rÃ©siduelles

| Configuration | Accuracy | Temps convergence |
|---------------|----------|-------------------|
| Sans skip connections | 89.2% Â± 0.6% | 45 epochs |
| Avec skip connections | **94.8% Â± 0.3%** | **25 epochs** |

### Impact de la BatchNorm

| Configuration | Accuracy | StabilitÃ© |
|---------------|----------|-----------|
| Sans BatchNorm | 87.4% Â± 1.2% | Faible |
| Avec BatchNorm | **94.8% Â± 0.3%** | **Ã‰levÃ©e** |

## ğŸ“Š Analyse des Performances

### Points forts observÃ©s :
- **Convergence rapide** : 25-30 epochs suffisent
- **GÃ©nÃ©ralisation excellente** : faible Ã©cart train/test
- **Robustesse** : performances stables sur multiple runs
- **EfficacitÃ©** : bon rapport performance/complexitÃ©

### DÃ©fis identifiÃ©s :
- **Classes similaires** : confusion Chat/Chien, T-shirt/Chemise
- **DonnÃ©es dÃ©sÃ©quilibrÃ©es** : nÃ©cessite des techniques spÃ©ciales
- **Ressources** : modÃ¨les profonds demandent beaucoup de GPU

## ğŸ“Œ AmÃ©liorations Futures

### Court terme
- [ ] ImplÃ©menter Focal Loss pour classes dÃ©sÃ©quilibrÃ©es
- [ ] Ajouter Grad-CAM pour interprÃ©tabilitÃ©
- [ ] Optimiser avec Mixed Precision Training
- [ ] Tests unitaires complets

### Long terme
- [ ] IntÃ©gration Vision Transformers + ResNet
- [ ] Neural Architecture Search (NAS)
- [ ] Quantization pour dÃ©ploiement mobile
- [ ] Apprentissage auto-supervisÃ©

### Nouvelles architectures Ã  explorer
- [ ] EfficientNet v2
- [ ] ConvNeXt
- [ ] Swin Transformer
- [ ] RegNet

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! Veuillez :
1. Fork le projet
2. CrÃ©er une branche feature (`git checkout -b feature/amazing-feature`)
3. Commit vos changements (`git commit -m 'Add amazing feature'`)
4. Push sur la branche (`git push origin feature/amazing-feature`)
5. Ouvrir une Pull Request

## ğŸ“„ Structure du Projet

```
Image-Classification-with-ResNet/
â”œâ”€â”€ src/                    # Code source
â”œâ”€â”€ notebooks/              # Jupyter notebooks
â”œâ”€â”€ configs/               # Configurations
â”œâ”€â”€ results/               # RÃ©sultats et modÃ¨les
â”œâ”€â”€ docs/                  # Documentation
â””â”€â”€ tests/                 # Tests unitaires
```

## ğŸ‘¥ Auteurs

**Ã‰tudiants :**
- **Marwane Ouzaina** - [GitHub](https://github.com/marwaneouz)
- **Chaima Khninich**

**Encadrants :**
- **Pr. Aissam Hadri**
- **Pr. Ahmed Alhayani**
- **Pr. Mohamed Benadd**

**Institution :** UniversitÃ© Ibn Zohr - FacultÃ© Polydisciplinaire de Ouarzazate  
**Formation :** Master IMSD  
**AnnÃ©e :** 2024/2025

## ğŸ“œ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ“§ Contact

Pour toute question ou suggestion :
- Email : marwaneouzaina@gmail.com
- LinkedIn : [Marwane Ouzaina](www.linkedin.com/in/marwane-ouzaina-a46200322)

---

<div align="center">
  â­ N'hÃ©sitez pas Ã  mettre une Ã©toile si ce projet vous a Ã©tÃ© utile !
</div>
